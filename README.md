# Song Popularity and Music Metrics

Data is extracted from Spotify using the Spotify API and from the Million Song Subset from the Million Song Database. Methods from the Spotipy package are used for data exchange with the Spotify database in extracting top song data in JSON format. The Million Song Subset is downloaded from GitHub as a CSV file and imported into a Google Sheets document where it can be read from a Jupyter Notebook. The Million Song Database includes data from Echo Nest on the most popular contemporary songs including technical data on musical measures and metrics of individual songs.The Spotify database includes data for over a hundred million songs on the platform including categorical data on the identifying information of songs and quantitative data on the popularity of music.

Data used from the Million Song Subset includes artist and song hotness, initial beat and tatum times, fade-in and fade-out times, artist familiarity and location, key, loudness, mode, tempo, genre, time signature, song name, and year. Only songs with a hotness rating greater than 0.5 were integrated. The song names are queried for in the Spotify database using Spotipy’s search method and the album name, artist, artist ID, duration, explicitness, song ID, name and popularity is fetched for each. These datasets are joined, creating a dataset that allows for greater insight on music patterns and popularity. The resulting dataframe is normalized and aggregated to reduce redundancy, group related columns and rollup data into a more usable format.

Extracting the data is a significant challenge. The Spotify API currently doesn’t support a method that returns all tracks with given conditions. As a result, queries need to be made for each song individually. Running over a thousand queries in a loop exceeds Spotify’s rate limits so the time library is used to implement a slight delay. However, this process can take a long time, so a half second delay is included only for every hundred queries. Regardless, Spotify’s data had very few inconsistencies and was very easy to clean and filter. Considering the magnitude of the Million Song Dataset, the Million Song Dataset has a significant amount of NaN values. Fortunately, the NaN values mostly reside in columns that are redundant or unnecessary in examining the desired relationship. Dropping columns and filtering rows allows all NaN values to be removed from all columns.

![Image](https://github.com/user-attachments/assets/c676e307-c59b-4def-b58f-42de03fec705)

A thorough explanation with visualizations may be viewed on YouTube: https://www.youtube.com/watch?v=8XV-8EQ7HhI
